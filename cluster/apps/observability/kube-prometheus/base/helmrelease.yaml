---
# yaml-language-server: $schema=https://schemas.budimanjojo.com/helm.toolkit.fluxcd.io/helmrelease_v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
spec:
  interval: 1h
  chartRef:
    kind: OCIRepository
    name: kube-prometheus-stack
  values:
    cleanPrometheusOperatorObjectNames: true

    alertmanager:
      route:
        main:
          enabled: true
          hostnames:
            - alertmanager.${SECRET_DOMAIN_0}
          parentRefs:
            - name: internal
              namespace: networking-system
              sectionName: https-0
      alertmanagerSpec:
        alertmanagerConfiguration:
          name: alertmanager
        externalUrl: https://alertmanager.${SECRET_DOMAIN_0}
        storage:
          volumeClaimTemplate:
            spec:
              storageClassName: rook-ceph-block
              resources:
                requests:
                  storage: 1Gi

    kubeEtcd:
      service:
        selector:
          component: kube-apiserver # etcd runs on controlplane nodes

    kubeProxy:
      enabled: false

    prometheus:
      route:
        main:
          enabled: true
          hostnames: ["prom.${SECRET_DOMAIN_0}"]
          parentRefs:
            - name: internal
              namespace: networking-system
              sectionName: https-0
      prometheusSpec:
        externalUrl: https://prom.${SECRET_DOMAIN_0}
        podMonitorSelectorNilUsesHelmValues: false
        probeSelectorNilUsesHelmValues: false
        ruleSelectorNilUsesHelmValues: false
        scrapeConfigSelectorNilUsesHelmValues: false
        serviceMonitorSelectorNilUsesHelmValues: false
        retention: 7d
        retentionSize: 25GB
        resources:
          requests:
            cpu: 100m
          limits:
            memory: 2000Mi
        storageSpec:
          volumeClaimTemplate:
            spec:
              storageClassName: rook-ceph-block
              resources:
                requests:
                  storage: 25Gi

    prometheus-node-exporter:
      fullnameOverride: node-exporter

    kube-state-metrics:
      fullnameOverride: kube-state-metrics

    grafana:
      enabled: false
      forceDeployDashboards: true
      operator:
        dashboardsConfigMapRefEnabled: true
        folder: observability
        matchLabels:
          grafana.internal/instance: grafana

    additionalPrometheusRulesMap:
      dockerhub-rules:
        groups:
          - name: dockerhub
            rules:
              - alert: DockerhubRateLimitRisk
                annotations:
                  summary: There are {{ $value }} containers pulling from Dockerhub. This may lead to rate limiting.
                expr: count(time() - container_last_seen{image=~"(docker.io).*",container!=""} < 30) > 100
                labels:
                  severity: critical
      oom-rules:
        groups:
          - name: oom
            rules:
              - alert: OomKilled
                annotations:
                  summary: Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.
                expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
                labels:
                  severity: critical
    # serviceMonitor:
    #   scrapeTimeout: 60s
    # kubeControllerManager:
    #   enabled: true
    #   endpoints:
    #     - 192.168.200.21
    #     - 192.168.200.22
    #     - 192.168.200.23
    # kubeScheduler:
    #   enabled: true
    #   endpoints:
    #     - 192.168.200.21
    #     - 192.168.200.22
    #     - 192.168.200.23
